{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load datasets\n",
    "trainset = pd.read_csv(\"train.csv\")\n",
    "testset = pd.read_csv(\"test.csv\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create sets\n",
    "text = trainset[\"comment_text\"]\n",
    "toxic_score = trainset[\"toxic\"]\n",
    "severe_toxic_score = trainset[\"severe_toxic\"]\n",
    "obscene_score = trainset[\"obscene\"]\n",
    "threat_score = trainset[\"threat\"]\n",
    "insult_score = trainset[\"insult\"]\n",
    "identity_hate_score = trainset[\"identity_hate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    86614\n",
       "1     9237\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocess\n",
    "toxic_score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:  9.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.990\n",
      "Best parameters set:\n",
      "\tclf__alpha: 1e-05\n",
      "\tclf__penalty: 'elasticnet'\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "#pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "    #'clf__n_iter': (10, 50, 80),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(text, severe_toxic_score)\n",
    "\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=5e-06, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train a SGD classifier  - Toxic\n",
    "toxic_count_vect = TfidfVectorizer(max_df = 0.5,ngram_range=(1,1))\n",
    "X = toxic_count_vect.fit_transform(text)\n",
    "y = toxic_score\n",
    "ToxicEstimator = SGDClassifier(penalty=\"elasticnet\",alpha=0.000005,loss=\"log\")\n",
    "\n",
    "#completely fit\n",
    "ToxicEstimator.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=5e-06, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train a SGD classifier  - severe_toxic\n",
    "severe_count_vect = TfidfVectorizer(max_df = 0.75,ngram_range=(1,2))\n",
    "X = severe_count_vect.fit_transform(text)\n",
    "y = severe_toxic_score\n",
    "SevToxicEstimator = SGDClassifier(penalty=\"elasticnet\",alpha=0.000005,loss=\"log\")\n",
    "\n",
    "#completely fit\n",
    "SevToxicEstimator.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=5e-06, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train a SGD classifier  - obscene\n",
    "obscene_count_vect = TfidfVectorizer(max_df = 0.75,ngram_range=(1,2))\n",
    "X = obscene_count_vect.fit_transform(text)\n",
    "y = obscene_score\n",
    "obsceneEstimator = SGDClassifier(penalty=\"elasticnet\",alpha=0.000005,loss=\"log\")\n",
    "\n",
    "#completely fit\n",
    "obsceneEstimator.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=5e-06, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train a SGD classifier  - threat\n",
    "threat_count_vect = TfidfVectorizer(max_df = 0.75,ngram_range=(1,2))\n",
    "X = threat_count_vect.fit_transform(text)\n",
    "y = threat_score\n",
    "threatEstimator = SGDClassifier(penalty=\"elasticnet\",alpha=0.000005,loss=\"log\")\n",
    "\n",
    "#completely fit\n",
    "threatEstimator.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=5e-06, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train a SGD classifier  - insult\n",
    "insult_count_vect = TfidfVectorizer(max_df = 0.75,ngram_range=(1,2))\n",
    "X = insult_count_vect.fit_transform(text)\n",
    "y = insult_score\n",
    "insultEstimator = SGDClassifier(penalty=\"elasticnet\",alpha=0.000005,loss=\"log\")\n",
    "\n",
    "#completely fit\n",
    "insultEstimator.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=5e-06, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train a SGD classifier  - id\n",
    "id_count_vect = TfidfVectorizer(max_df = 0.75,ngram_range=(1,2))\n",
    "X = id_count_vect.fit_transform(text)\n",
    "y = identity_hate_score\n",
    "idEstimator = SGDClassifier(penalty=\"elasticnet\",alpha=0.000005,loss=\"log\")\n",
    "\n",
    "#completely fit\n",
    "idEstimator.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,0.9,0.0,0.6,0.0,0.0,0.0'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_output(id_num,text):\n",
    "    #vectorize\n",
    "    text = [text]\n",
    "    toxic_vec = toxic_count_vect.transform(text)\n",
    "    sev_toxic_vec = severe_count_vect.transform(text)\n",
    "    obscene_vec = obscene_count_vect.transform(text)\n",
    "    threat_vec = threat_count_vect.transform(text)\n",
    "    insult_vec = insult_count_vect.transform(text)\n",
    "    id_vec = id_count_vect.transform(text)\n",
    "    #predict\n",
    "    toxic_value = \"{0:.1f}\".format(ToxicEstimator.predict_proba(toxic_vec)[0][1])\n",
    "    sev_toxic_value = \"{0:.1f}\".format(SevToxicEstimator.predict_proba(sev_toxic_vec)[0][1])   \n",
    "    obs_value = \"{0:.1f}\".format(obsceneEstimator.predict_proba(obscene_vec)[0][1])\n",
    "    threat_value = \"{0:.1f}\".format(threatEstimator.predict_proba(threat_vec)[0][1])\n",
    "    insult_value = \"{0:.1f}\".format(threatEstimator.predict_proba(insult_vec)[0][1])\n",
    "    id_value = \"{0:.1f}\".format(idEstimator.predict_proba(id_vec)[0][1])\n",
    "    return(str(id_num)+\",\"+toxic_value +\",\"+sev_toxic_value+\",\"+obs_value+\",\"+threat_value+\",\"+insult_value+\",\"+id_value)\n",
    "\n",
    "get_output(1,\"Is non other than an ungraceful dick!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from_zero = False\n",
    "start_from = 52300\n",
    "if from_zero:\n",
    "    f = open('present.csv','w')\n",
    "    f.write('id,toxic,severe_toxic,obscene,threat,insult,identity_hate')\n",
    "    for item in testset.iterrows():\n",
    "        id_num =item[1][0]\n",
    "        text = item[1][1]\n",
    "        result = get_output(id_num,str(text))\n",
    "        f.write('\\n')\n",
    "        f.write(result)\n",
    "    f.close()\n",
    "else:\n",
    "    f = open('present.csv','a')\n",
    "    for item in testset.iloc[start_from:].iterrows():\n",
    "        id_num =item[1][0]\n",
    "        text = item[1][1]\n",
    "        result = get_output(id_num,str(text))\n",
    "        f.write('\\n')\n",
    "        f.write(result)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,0.1,0.0,0.0,0.0,0.0,0.0'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.iloc[52296:].head()\n",
    "get_output(1,'N/A')\n",
    "#testset.iloc[52300][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
